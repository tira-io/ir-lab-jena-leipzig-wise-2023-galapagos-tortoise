{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import ensure_pyterrier_is_loaded, persist_and_normalize_run\n",
    "from tira.rest_api_client import Client\n",
    "import pyterrier as pt\n",
    "from ir_measures import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terrier-assemblies 5.9 jar-with-dependencies not found, downloading to /home/codespace/.pyterrier...\n",
      "Done\n",
      "terrier-python-helper 0.0.8 jar not found, downloading to /home/codespace/.pyterrier...\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.1 has loaded Terrier 5.9 (built by craigm on 2024-05-02 17:40) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "pt.init()\n",
    "ensure_pyterrier_is_loaded()\n",
    "tira = Client()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_dataset = pt.get_dataset(\"irds:ir-lab-padua-2024/longeval-2023-01-20240426-training\")\n",
    "pt_dataset_jun = pt.get_dataset(\"irds:ir-lab-padua-2024/longeval-2023-06-20240418-training\")\n",
    "pt_dataset_aug = pt.get_dataset(\"irds:ir-lab-padua-2024/longeval-2023-08-20240418-training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = tira.pt.from_submission('ir-benchmarks/tira-ir-starter/BM25 Re-Rank (tira-ir-starter-pyterrier)', 'ir-benchmarks/longeval-2023-01-20240423-training')\n",
    "sce = tira.pt.from_submission('ir-benchmarks/fschlatt/sparse-cross-encoder-4-512', 'ir-benchmarks/longeval-2023-01-20240423-training')\n",
    "cb = tira.pt.from_submission('ir-benchmarks/tira-ir-starter/ColBERT Re-Rank (tira-ir-starter-pyterrier)', 'ir-benchmarks/longeval-2023-01-20240423-training')\n",
    "rz = tira.pt.from_submission('workshop-on-open-web-search/fschlatt/rank-zephyr', 'ir-benchmarks/longeval-2023-01-20240423-training')\n",
    "fusion = pt.transformer.get_transformer(pt.io.read_results('galapagos-tortoise-wsum.lag1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nDCG(judged_only=True)@10</th>\n",
       "      <th>nDCG(judged_only=True)</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>nDCG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WSum</td>\n",
       "      <td>0.454667</td>\n",
       "      <td>0.480725</td>\n",
       "      <td>0.251512</td>\n",
       "      <td>0.355077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RankZephyr</td>\n",
       "      <td>0.455142</td>\n",
       "      <td>0.482076</td>\n",
       "      <td>0.246549</td>\n",
       "      <td>0.352920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparse Cross-Encoder</td>\n",
       "      <td>0.448109</td>\n",
       "      <td>0.474784</td>\n",
       "      <td>0.220869</td>\n",
       "      <td>0.336719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ColBERT</td>\n",
       "      <td>0.450091</td>\n",
       "      <td>0.476047</td>\n",
       "      <td>0.216457</td>\n",
       "      <td>0.330096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.444411</td>\n",
       "      <td>0.472638</td>\n",
       "      <td>0.199380</td>\n",
       "      <td>0.317285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  nDCG(judged_only=True)@10  nDCG(judged_only=True)  \\\n",
       "4                  WSum                   0.454667                0.480725   \n",
       "3            RankZephyr                   0.455142                0.482076   \n",
       "1  Sparse Cross-Encoder                   0.448109                0.474784   \n",
       "2               ColBERT                   0.450091                0.476047   \n",
       "0                  BM25                   0.444411                0.472638   \n",
       "\n",
       "    nDCG@10      nDCG  \n",
       "4  0.251512  0.355077  \n",
       "3  0.246549  0.352920  \n",
       "1  0.220869  0.336719  \n",
       "2  0.216457  0.330096  \n",
       "0  0.199380  0.317285  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [\n",
    "        bm25,\n",
    "        sce,\n",
    "        cb,\n",
    "        rz,\n",
    "        fusion,\n",
    "    ],\n",
    "    pt_dataset.get_topics('text'),\n",
    "    pt_dataset.get_qrels(),\n",
    "    names=[\n",
    "        'BM25', \n",
    "        \"Sparse Cross-Encoder\",\n",
    "        'ColBERT',\n",
    "        'RankZephyr', \n",
    "        'WSum',\n",
    "        # \"3-max-avg\",\n",
    "    ],\n",
    "    eval_metrics=[nDCG(judged_only=True)@10, nDCG(judged_only=True), nDCG@10, nDCG],\n",
    ").sort_values(by=\"nDCG@10\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Test on June-Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The download is derived from The LongEval Dataset under the \"Qwant LongEval Attribution-NonCommercial-ShareAlike License\". Hence, the download is also under this License. By using it, you agree to the terms of this license. Please find details at: https://lindat.mff.cuni.cz/repository/xmlui/page/Qwant_LongEval_BY-NC-SA_License\n",
      "Download from the Incubator: https://files.webis.de/data-in-production/data-research/tira-zenodo-dump-preparation/ir-lab-padua2024/longeval-2023-06-20240418-truth.zip?download=1\n",
      "\tThis is only used for last spot checks before archival to Zenodo.\n",
      "Code: 404\n",
      "Error occured while fetching https://files.webis.de/data-in-production/data-research/tira-zenodo-dump-preparation/ir-lab-padua2024/longeval-2023-06-20240418-truth.zip?download=1. I will sleep 14 seconds and continue.\n",
      "Code: 404\n",
      "Error occured while fetching https://files.webis.de/data-in-production/data-research/tira-zenodo-dump-preparation/ir-lab-padua2024/longeval-2023-06-20240418-truth.zip?download=1. I will sleep 6 seconds and continue.\n",
      "Code: 404\n",
      "Error occured while fetching https://files.webis.de/data-in-production/data-research/tira-zenodo-dump-preparation/ir-lab-padua2024/longeval-2023-06-20240418-truth.zip?download=1. I will sleep 4 seconds and continue.\n",
      "Code: 404\n",
      "Error occured while fetching https://files.webis.de/data-in-production/data-research/tira-zenodo-dump-preparation/ir-lab-padua2024/longeval-2023-06-20240418-truth.zip?download=1. I will sleep 14 seconds and continue.\n",
      "Code: 404\n",
      "Error occured while fetching https://files.webis.de/data-in-production/data-research/tira-zenodo-dump-preparation/ir-lab-padua2024/longeval-2023-06-20240418-truth.zip?download=1. I will sleep 15 seconds and continue.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/codespace/.tira/extracted_datasets/ir-lab-padua-2024/longeval-2023-06-20240418-training//longeval-2023-06-20240418-training' -> '/home/codespace/.tira/extracted_datasets/ir-lab-padua-2024/longeval-2023-06-20240418-training/truth-data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m pt\u001b[38;5;241m.\u001b[39mExperiment(\n\u001b[1;32m      2\u001b[0m     [\n\u001b[1;32m      3\u001b[0m         bm25,\n\u001b[1;32m      4\u001b[0m         sce,\n\u001b[1;32m      5\u001b[0m         cb,\n\u001b[1;32m      6\u001b[0m         rz,\n\u001b[1;32m      7\u001b[0m         fusion,\n\u001b[1;32m      8\u001b[0m     ],\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mpt_dataset_jun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#pt_dataset_jun.get_qrels(),\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m01_qrels_jun.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     12\u001b[0m     names\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBM25\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSparse Cross-Encoder\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColBERT\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRankZephyr\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     17\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWSum\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m     ],\n\u001b[1;32m     19\u001b[0m     eval_metrics\u001b[38;5;241m=\u001b[39m[nDCG(judged_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m@\u001b[39m\u001b[38;5;241m10\u001b[39m, nDCG(judged_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), nDCG\u001b[38;5;241m@\u001b[39m\u001b[38;5;241m10\u001b[39m, nDCG],\n\u001b[1;32m     20\u001b[0m     baseline \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m     21\u001b[0m )\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnDCG\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/pyterrier/datasets.py:445\u001b[0m, in \u001b[0;36mIRDSDataset.get_topics\u001b[0;34m(self, variant, tokenise_query)\u001b[0m\n\u001b[1;32m    443\u001b[0m qcls \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mqueries_cls()\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m variant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m variant \u001b[38;5;129;01min\u001b[39;00m qcls\u001b[38;5;241m.\u001b[39m_fields[\u001b[38;5;241m1\u001b[39m:], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_irds_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m only supports the following topic variants \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqcls\u001b[38;5;241m.\u001b[39m_fields[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 445\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueries_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    447\u001b[0m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqid\u001b[39m\u001b[38;5;124m\"\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# pyterrier uses \"qid\"\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m variant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;66;03m# Some datasets have a query field called \"query\". We need to remove it or\u001b[39;00m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;66;03m# we'll end up with multiple \"query\" columns, which will cause problems\u001b[39;00m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# because many components are written assuming no columns have the same name.\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tira/ir_datasets_util.py:175\u001b[0m, in \u001b[0;36m__queries.<locals>.DynamicQueries.queries_iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mqueries_iter\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m deepcopy(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mvalues()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tira/ir_datasets_util.py:189\u001b[0m, in \u001b[0;36m__queries.<locals>.DynamicQueries.__get_queries\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqueries \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     ret \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m stream_all_lines(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_input_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    190\u001b[0m         orig_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_query\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m i \u001b[38;5;28;01melse\u001b[39;00m i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_query\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    191\u001b[0m         description \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m orig_query \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(orig_query) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mdict\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m orig_query) \u001b[38;5;28;01melse\u001b[39;00m orig_query[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tira/ir_datasets_util.py:184\u001b[0m, in \u001b[0;36m__queries.<locals>.DynamicQueries.get_input_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_file) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_file\n\u001b[0;32m--> 184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/queries.jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tira/ir_datasets_util.py:276\u001b[0m, in \u001b[0;36mir_dataset_from_tira_fallback_to_original_ir_datasets.<locals>.IrDatasetsFromTira.load.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    274\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoad ir_dataset \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m from tira.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    275\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy_docs(\u001b[38;5;28;01mlambda\u001b[39;00m: get_download_dir_from_tira(dataset_id, \u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 276\u001b[0m queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy_queries(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mget_download_dir_from_tira\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    277\u001b[0m qrels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlazy_qrels(\u001b[38;5;28;01mlambda\u001b[39;00m: get_download_dir_from_tira(dataset_id, \u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    278\u001b[0m ret \u001b[38;5;241m=\u001b[39m Dataset(docs, queries, qrels)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tira/ir_datasets_util.py:267\u001b[0m, in \u001b[0;36mir_dataset_from_tira_fallback_to_original_ir_datasets.<locals>.get_download_dir_from_tira\u001b[0;34m(tira_path, truth_dataset)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtira\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrest_api_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client \u001b[38;5;28;01mas\u001b[39;00m RestClient\n\u001b[1;32m    266\u001b[0m task, dataset \u001b[38;5;241m=\u001b[39m tira_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRestClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruth_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruth_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tira/rest_api_client.py:375\u001b[0m, in \u001b[0;36mClient.download_dataset\u001b[0;34m(self, task, dataset, truth_dataset)\u001b[0m\n\u001b[1;32m    372\u001b[0m data_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-training\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_and_extract_zip(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data-download/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/input-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m\u001b[38;5;250m \u001b[39mtruth_dataset\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.zip\u001b[39m\u001b[38;5;124m'\u001b[39m, target_dir)\n\u001b[0;32m--> 375\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target_dir \u001b[38;5;241m+\u001b[39m suffix\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/codespace/.tira/extracted_datasets/ir-lab-padua-2024/longeval-2023-06-20240418-training//longeval-2023-06-20240418-training' -> '/home/codespace/.tira/extracted_datasets/ir-lab-padua-2024/longeval-2023-06-20240418-training/truth-data'"
     ]
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [\n",
    "        bm25,\n",
    "        sce,\n",
    "        cb,\n",
    "        rz,\n",
    "        fusion,\n",
    "    ],\n",
    "    pt_dataset_jun.get_topics('text'),\n",
    "    pt_dataset_jun.get_qrels(),\n",
    "    #pd.read_csv(\"01_qrels_jun.txt\"),\n",
    "    names=[\n",
    "        'BM25', \n",
    "        \"Sparse Cross-Encoder\",\n",
    "        'ColBERT',\n",
    "        'RankZephyr', \n",
    "        'WSum',\n",
    "    ],\n",
    "    eval_metrics=[nDCG(judged_only=True)@10, nDCG(judged_only=True), nDCG@10, nDCG],\n",
    "    baseline = 4\n",
    ").sort_values(by=\"nDCG\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Test on August-Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo_aug = pt.Experiment(\n",
    "    [\n",
    "        bm25,\n",
    "        sce,\n",
    "        cb,\n",
    "        rz,\n",
    "        fusion,\n",
    "    ],\n",
    "    pt_dataset_aug.get_topics('text'),\n",
    "    pt_dataset_aug.get_qrels(),\n",
    "    names=[\n",
    "        'BM25', \n",
    "        \"Sparse Cross-Encoder\",\n",
    "        'ColBERT',\n",
    "        'RankZephyr', \n",
    "        'WSum',\n",
    "    ],\n",
    "    eval_metrics=[nDCG(judged_only=True)@10, nDCG(judged_only=True), nDCG@10, nDCG],\n",
    "    baseline = 4\n",
    ").sort_values(by=\"nDCG\", ascending=False)\n",
    "\n",
    "hypo_aug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
